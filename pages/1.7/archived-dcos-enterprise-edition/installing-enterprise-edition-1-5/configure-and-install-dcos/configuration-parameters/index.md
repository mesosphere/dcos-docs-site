---
layout: layout.pug
navigationTitle:  Configuration parameters
title: Configuration parameters
menuWeight: 0
excerpt:
enterprise: true
featureMaturity:
---




These configuration parameters are specified in [YAML][1] format in your config.yaml file. During DC/OS installation the configuration file is used to generate a customized DC/OS build. <!-- A config.yaml template file is available [here][2]. -->

# <a name="config_cluster"></a>Cluster Configuration

These parameters specify your cluster configuration in the `config_cluster` section of the config.yaml file.

## <a name="bootstrap-url"></a>bootstrap_url

This parameter specifies the URI path for the DC/OS installer to store the customized DC/OS build files, which can be local (`bootstrap_url:file:///opt/dcos_install_tmp`) or hosted (`http://<your-web-server>`). By default this is set to `file:///opt/dcos_install_tmp` in the `config.yaml` template file, which is the location where the DC/OS installer puts your install tarball.

**Tip:** This parameter is for advanced users. The default value should work for most installations.

## <a name="cluster-name"></a>cluster_name

This parameter specifies the name of your cluster. For example:

    cluster_name: zk-example
    

## <a name="dns-search"></a>dns_search

<!-- optional -->

This parameter specifies a space-separated list of domains that are tried when an unqualified domain is entered (e.g. domain searches that do not contain '.'). The Linux implementation of `/etc/resolv.conf` restricts the maximum number of domains to 6 and the maximum number of characters the setting can have to 256. For more information, see [man /etc/resolv.conf][2].

A `search` line with the specified contents is added to the `/etc/resolv.conf` file of every cluster host. `search` can do the same things as `domain` and is more extensible because multiple domains can be specified.

In this example, `example.com` has public website `www.example.com` and all of the hosts in the datacenter have fully qualified domain names that end with `dc1.example.com`. One of the hosts in your datacenter has the hostname `foo.dc1.example.com`. If `dns_search` is set to 'dc1.example.com example.com', then every DC/OS host which does a name lookup of foo will get the A record for `foo.dc1.example.com`. If a machine looks up `www`, first `www.dc1.example.com` would be checked, but it does not exist, so the search would try the next domain, lookup `www.example.com`, find an A record, and then return it.

    dns_search: dc1.example.com dc1.example.com example.com dc1.example.com dc2.example.com example.com
    

## <a name="docker-remove"></a>docker_remove_delay

<!-- optional -->

This parameter specifies the amount of time to wait before removing the Docker image generated by the installer. It is recommended that you accept the default value 1 hour.

## <a name="exhibitor-storage"></a>exhibitor_storage_backend

This parameter specifies the type of Exhibitor storage backend. During DC/OS installation, a storage system is required for configuring and orchestrating Zookeeper with Exhibitor on the master nodes. Exhibitor automatically configures your Zookeeper installation on the master nodes during your DC/OS installation. The available options are `zookeeper`, `aws_s3`, and `shared_filesystem`:

*   zookeeper
    :   *   exhibitor_zk_hosts
            :   This parameter specifes the location of a bootstrap ZooKeeper (ZK) instance. This ZK instance must be a production cluster that is separate from the DC/OS internal ZK instance. This cluster is only used for configuring the internal Exhibitor instances. Specify the value as a comma-separated list of one or more ZK node IP addresses, and the port number.
            
            **Tip:** You can set up a temporary ZK bootstrap instance by running this command on your installer machine. This temporary ZK instance is for testing purposes only and should not be used in a production environment:
            
                docker run -d -p 2181:2181 -p 2888:2888 -p 3888:3888 jplock/zookeeper
                
            
            And then set the `exhibitor_zk_hosts` key to a value of `$INSTALLER_HOST_IP_ADDRESS:2181`.
        
        *   exhibitor_zk_path
            :   This parameter specifies the filepath that Exhibitor uses to store data, including the zoo.cfg file.
    
    Here is a ZK example, where the `$INSTALLER_HOST_IP_ADDRESS` is `10.10.10.1` and `$PORT` is `2181`:
    
        exhibitor_storage_backend: zookeeper
        exhibitor_zk_hosts: 10.10.10.1:2181
        exhibitor_zk_path: /zk-example
        

*   aws_s3 :
    
    *   aws_access_key_id
        :   This parameter specifies AWS key ID.
    
    *   aws_region
        :   This parameter specifies AWS region for your S3 bucket.
    
    *   aws_secret_access_key
        :   This parameter specifies AWS secret access key.
    
    *   s3_bucket
        :   This parameter specifies name of your S3 bucket.
    
    *   s3_prefix
        :   This parameter specifies S3 prefix to be used within your S3 bucket to be used by Exhibitor.
        
        Here is an aws_s3 example:
        
            exhibitor_storage_backend: aws_s3
            aws_access_key_id: AKIAIOSFODNN7EXAMPLE
            aws_secret_access_key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
            aws_region: us-west-2
            s3_bucket: mybucket
            s3_prefix: s3-example
            
    
    *   shared_filesystem :
        
        *   exhibitor_fs_config_dir : This parameter specifies the absolute path to the folder that Exhibitor uses to coordinate its configuration. This should be a directory inside of a Network File System (NFS) mount. For example, if every master has `/fserv` mounted via NFS, set as `exhibitor_fs_config_dir: /fserv/dcos-exhibitor`.
        
        **Important:** With `shared_filesystem`, all masters must must have the NFS volume mounted and `exhibitor_fs_config_dir` must be inside of it. If any of your servers are missing the mount, the DC/OS cluster will not start.
        
        Here is a shared_filesystem example:
        
            exhibitor_storage_backend: shared_filesystem
            exhibitor_fs_config_dir: /shared-mount
            

## <a name="gc-delay"></a>gc_delay

<!-- optional -->

This parameter specifies th maximum amount of time to wait before cleaning up the executor directories. It is recommended that you accept the default value of 2 days.

## <a name="master"></a>master_discovery

This parameter specifies the Mesos master discovery method:

*   static
    
    :   Use the Mesos agents to discover the masters by giving each agent a static list of master IPs. The masters must not change IP addresses, and if a master is replaced, the new master must take the old master's IP address. For example:
        
            master_discovery: static
            
    
    *   master_list
        
        :   Specify a list of your static master IP addresses as a YAML nested series (`-`). For example:
            
                master_list:
                - 172.17.10.101
                - 172.17.10.102
                - 172.17.10.103
                
            
            **Important:** Master nodes must be listed in both the `master_list` and `target_hosts` parameters.

*   vrrp
    
    :   Use keepalived with a VIP. You are required to maintain this VIP infrastructure. For example:
        
            master_discovery: vrrp
            
    
    *   keepalived_router_id
        
        :   Specify the virtual router ID of the keepalived cluster. You must use the same virtual router ID across your cluster. For example:
            
                keepalived_router_id: 51
                
    
    *   keepalived_interface
        
        :   Specify the interface that keepalived uses. For example:
            
                keepalived_interface: eth1
                
    
    *   keepalived_pass
        
        :   If you've set your auth to PASS, specify the same password that you set in your configuration file. For example:
            
                keepalived_pass: $MY_STRONG_PASSWORD
                
    
    *   keepalived_virtual_ipaddress
        
        :   Specify the VIP in use by your keepalived cluster. For example:
            
                keepalived_virtual_ipaddress: 67.34.242.55
                

## <a name="num-masters"></a>num_masters

If `master_discovery: vrrp`, this parameter specifies the number of Mesos masters in your DC/OS cluster. For example:

    num_masters: 3
    

**Important:** If `master_discovery: static`, do not use the `num_masters` parameter.

## <a name="resolvers"></a>resolvers

This required parameters specifies a YAML-formatted nested series (`-`) of DNS resolvers for your DC/OS host nodes, or accept the default value of `8.8.8.8`. Set this parameter to the most authoritative nameservers that you have. If you want to resolve internal hostnames, set it to a nameserver that can resolve them. If you have no internal hostnames to resolve, it is acceptable to set this to a public nameserver like Google or AWS. For example:

    resolvers: - 8.8.8.8 - 8.8.4.4
    

*Caution:* If you set the `resolvers` parameter incorrectly, you will permanently damage your configuration and have to reinstall DC/OS.

## <a name="roles"></a>roles

This parameter specifies the Mesos roles to delegate to this node or accept the default value of `slave_public`. For more information, see <a href="https://open.mesosphere.com/reference/mesos-master/#roles" target="_blank">Mesos roles</a>.

*   slave_public
    
    :   Runs the public agent node. This is the default value. For example:
        
            roles: slave_public
            

*   master
    
    :   Runs the master node. For example:
        
            roles: master
            

*   slave
    
    :   Runs the private agent node. For example:
        
            roles: slave
            

## <a name="weights"></a>weights

<!-- optional --> This parameter specifies the priority of the role or accept the default value of

`weights: slave_public=1`. For more information, see <a href="https://open.mesosphere.com/reference/mesos-master/#weights" target="_blank">Mesos weights</a>.

# <a name="ssh_config"></a>SSH Configuration

These parameters specify the SSH credentials for your cluster in the `ssh_config` section of the config.yaml file. This information is used during DC/OS installation for `--preflight`, `--deploy`, `--postflight`, and `--clean-dcos` checks.

*   It's recommended to rotate keys in the cluster after deployment.
*   It's recommended to copy your private SSH key to the `genconf/` directory that is mounted to `/genconf` inside the installer Docker container. If you change this to a path on the host machine, the installer can't find the key because `/genconf` is mounted by default in the installer script.

<a name="log_directory"></a>log_directory

:   This parameter specifies the path to the installer host logs from the SSH processes. By default this is set to `/genconf/logs`. This should not be changed because `/genconf` is local to the container that is running the installer, and is a mounted volume. For example:
    
        log_directory: /genconf/logs
        

<a name="process_timeout"></a>process_timeout

:   This parameter specifies the allowable amount of time, in seconds, for an action to begin after the process forks. This parameter is not the complete process time. The default value is 120 seconds.

**Tip:** If have a slower network environment, consider changing to `process_timeout: 600`.

<a name="ssh_key_path"></a>ssh_key_path

:   This parameters specifies the path to the installer uses to log into the target nodes. By default this is set to `/genconf/ssh_key`. This parameter should not be changed because `/genconf` is local to the container that is running the installer, and is a mounted volume.

<a name="ssh_port"></a>ssh_port

:   This parameter specifies the default SSH port. For example:
    
        ssh_port: `22`
        

<a name="ssh_user"></a>ssh_user

:   This parameter specifies the default SSH username that is used to SSH into the target machines during installation. Users must have root privileges on the host machines. For example:
    
        ssh_user: vagrant
        

<a name="target_hosts"></a>target_hosts

:   This parameter specifies a complete list of IPv4 addresses to your agent and master nodes. This must be a YAML-formatted nested series (`-`). For example:
    
        target_hosts: 
        - <target-host-1> 
        - <target-host-2> 
        - <target-host-3> 
        - <target-host-4> 
        - <target-host-5>
        
    
    **Important:** Master nodes must be listed in both the `master_list` and `target_hosts` parameters.

# <a name="examples1"></a>Example YAML configuration files

#### DC/OS cluster with 3 masters, an Exhibitor/Zookeeper backed by Zookeeper, master list specified, Google DNS resolvers, and SSH configuration specified

<!-- You can find this configuration in the config.yaml [template file][3]. -->

        cluster_config:
          bootstrap_url: 'file:///opt/dcos_install_tmp'
          cluster_name: '<cluster-name>'
          exhibitor_storage_backend: zookeeper
          exhibitor_zk_hosts: <host1>:<port1>
          exhibitor_zk_path: /dcos
          master_discovery: static 
          master_list:
          - <master-ip-1>
          - <master-ip-2>
          - <master-ip-3>
          resolvers:
          - <dns-resolver-1>
          - <dns-resolver-2>
    
        ssh_config:
          log_directory: /genconf/logs
          process_timeout: 120
          ssh_key_path: /genconf/ssh-key
          ssh_port: '<port-number>'
          ssh_user: <username>
          target_hosts:
          - <target-host-1>
          - <target-host-2>
          - <target-host-3>
          - <target-host-4>
          - <target-host-5>
    

#### <a name="shared"></a>DC/OS cluster with 3 masters, an Exhibitor/Zookeeper shared filesystem storage backend, Internal DNS

    cluster_config:
      cluster_name: fs-example
      master_discovery: static
      exhibitor_storage_backend: shared_filesystem
      exhibitor_fs_config_dir: /shared-mount
      bootstrap_url: file:///tmp/dcos
      resolvers:
      - 0.10.5.1
      - 10.10.6.1
      roles: slave_public
      weights: slave_public=1
    
    ssh_config:
      log_directory: /genconf/logs
      process_timeout: 120
      ssh_key_path: /genconf/ssh-key
      ssh_port: '<port-number>'
      ssh_user: <username>
      target_hosts:
      - <target-host-1>
      - <target-host-2>
      - <target-host-3>
      - <target-host-4>
      - <target-host-5>
    

#### <a name="aws"></a>DC/OS Cluster with 3 masters, an Exhibitor/Zookeeper backed by an AWS S3 bucket, and AWS DNS

    cluster_config:
      cluster_name: s3-example
      master_discovery: static
      exhibitor_storage_backend: aws_s3
      aws_access_key_id: AKIAIOSFODNN7EXAMPLE
      aws_secret_access_key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
      aws_region: us-west-2
      s3_bucket: mybucket
      s3_prefix: s3-example
      bootstrap_url: file:///tmp/dcos
      resolvers: 
      - 169.254.169.253
      roles: slave_public
      weights: slave_public=1
    
    ssh_config:
      log_directory: /genconf/logs
      process_timeout: 120
      ssh_key_path: /genconf/ssh-key
      ssh_port: '<port-number>'
      ssh_user: <username>
      target_hosts:
      - <target-host-1>
      - <target-host-2>
      - <target-host-3>
      - <target-host-4>
      - <target-host-5>
    

#### <a name="zk"></a>DC/OS cluster with 3 masters, an Exhibitor/Zookeeper backed by Zookeeper, Google DNS

    cluster_config:
        cluster_name: zk-example
        num_masters: 3
        exhibitor_storage_backend: zookeeper
        exhibitor_zk_hosts: 10.10.10.1:2181
        exhibitor_zk_path: /zk-example
        bootstrap_url: file:///tmp/dcos
        master_discovery: vrrp
        keepalived_router_id: 51
        keepalived_interface: eth1
        keepalived_pass: $MY_STRONG_PASSWORD
        keepalived_virtual_ipaddress: 67.34.242.55
        resolvers: 
        - 8.8.8.8
        - 8.8.4.4
        roles: slave_public
        weights: slave_public=1
    
    ssh_config:
        log_directory: /genconf/logs
        process_timeout: 120
        ssh_key_path: /genconf/ssh-key
        ssh_port: '<port-number>'
        ssh_user: <username>
        target_hosts:
        - <target-host-1>
        - <target-host-2>
        - <target-host-3>
        - <target-host-4>
        - <target-host-5>

 [1]: https://en.wikipedia.org/wiki/YAML
 [2]: http://man7.org/linux/man-pages/man5/resolv.conf.5.html