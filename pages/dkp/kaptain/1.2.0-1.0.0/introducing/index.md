---
layout: layout.pug
navigationTitle: Introducing Kaptain
title: Introducing Kaptain
excerpt: Deploy and manage machine learning models with ease
menuWeight: 1
---

![Kaptain](../img/d2iq-kaptain.png)

Kaptain is a general cloud-native, enterprise-grade, and end-to-end ML/AI platform. The product is a set of open
source products, including Kubeflow, with optimized configurations that supports end-to-end machine learning workflows.

Kaptain empowers Data Scientists and ML Engineers to run and scale their entire ML stack with much higher velocity on Kubernetes and Cloud-Native ecosystems.  Kaptain solves a key problem that enterprises face: How to get a return from your expensive AI investments? Promoting from prototype to production is often hard, but it does not have to be in this case, with Kaptain.

Kaptain natively integrates Horovod - an open source distributed training framework - to support distributed deep learning across multi-GPU and multi-node clusters. Horovod is compatible with the existing TensorFlow, PyTorch, and MXNet deep learning frameworks and makes distributed Deep Learning super fast and easy.

Kaptain is also pre-configured with Apache Spark, providing the ability to tap into large pools of CPUs and GPUs, on demand.

D2iQ's Kaptain leverages our expertise in Kubernetes, so that companies can run their machine learning workloads anywhere: in the cloud, on-premise, or in hybrid environments.
Kaptain is an opinionated distribution based on Kubeflow: everything you need to train, deploy, and scale models is packaged and tested, so you can rest assured that it works out of the box.


If you want to learn more, please read our [blog post for Kaptain](https://d2iq.com/blog/kudo-for-kubeflow-the-enterprise-machine-learning-platform).

## Kaptain's Features and Benefits

| **Features**                                      | **Benefits**                                                 |
| ------------------------------------------------- | ------------------------------------------------------------ |
| Out-of-the-box integration of Spark and Horovod   | No need to install additional libraries to create data pipelines or train Spark ML models on multiple CPUs or GPUs |
| Fully tested pre-baked notebook images            | A familiar environment that has been fully tested and integrates with all the shared resources (CPUs, GPUs) and data access controls needed to build and share models as a team |
|
| Train, tune, and deploy from a Jupyter notebook   | No context switching or credentials and CLI tools on individuals' laptops    |
| Enterprise-grade security controls and profiles   | Multi-tenancy? No problem!                                      |
| Day 2 operations                                  | Built-in lifecycle management operations such as updates and upgrades   |