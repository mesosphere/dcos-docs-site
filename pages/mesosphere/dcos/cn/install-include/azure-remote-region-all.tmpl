本指南希望您已经拥有基于 Universal 安装工具 `0.2` 运行的 DC/OS 群集。如需了解有关使用 Universal 安装工具运行 DC/OS 的更多信息，请参阅 [DC/OS 在 Azure 上使用 Universal 安装工具指南](/mesosphere/dcos/{{ model.folder_version }}/installing/evaluation/azure/)。

您将学习如何将其他基础架构放入 Azure 远程分域。通过使用 Azure VNET 的对等功能，远程分域将相互连接。

# 先决条件
- 使用 Universal 安装工具 0.2 模块设置的正在运行的 DC/OS Enterprise 群集
- 您的远程分域的子网范围

# 远程分域入门
我们期望您已经运行的 DC/OS 群集 `main.tf` 与此示例类似。要部署远程分域，我们必须对您的 `main.tf` 进行一些更改

```hcl
provider "azure" {}

# Used to determine your public IP for forwarding rules
data "http" "whatismyip" {
  url = "http://whatismyip.akamai.com/"
}

module "dcos" {
  source  = "dcos-terraform/dcos/aws"
  version = "~> 0.2.0"

  providers = {
    azure = "azure"
  }

  location                          = "West US"
  avset_platform_fault_domain_count = 3

  cluster_name        = "my-dcos-demo"
  ssh_public_key_file = "<path-to-public-key-file>"
  admin_ips           = ["${data.http.whatismyip.body}/32"]

  num_masters        = 3
  num_private_agents = 2
  num_public_agents  = 1

  dcos_version = "1.13.3"

  dcos_variant              = "ee"
  dcos_license_key_contents = "${file("./license.txt")}"

  # Make sure to set your credentials if you do not want the default EE
  # dcos_superuser_username      = "superuser-name"
  # dcos_superuser_password_hash = "${file("./dcos_superuser_password_hash.sha512")}"

  dcos_instance_os = "centos_7.6"
}

output "masters-ips" {
  value = "${module.dcos.masters-ips}"
}

output "cluster-address" {
  value = "${module.dcos.masters-loadbalancer}"
}

output "public-agents-loadbalancer" {
  value = "${module.dcos.public-agents-loadbalancer}"
}
```

## 共享配置选项
要创建远程分域及其基础架构，我们将使用与管理节点分域相同的底层模块。这也意味着，将存在像 `cluster_name`、`admin_ips` 和 `ssh_public_key_file`等两种基础架构均需要的一些信息。为了让操作更容易，您应该在每个模块中将使用的 `main.tf` 定义本地变量。

```hcl
#...

// lets define variables which are shared between all regions
locals {
  ssh_public_key_file = "~/.ssh/id_rsa.pub"
  cluster_name        = "my-dcos-demo"
  admin_ips           = ["${data.http.whatismyip.body}/32"]
}

#...
```

### 内部子网络
共享信息的一部分是在您的基础架构中使用了哪些内部子网。如果您未指定 `subnet_range`，则 terraform 使用默认值 `172.12.0.0/16`。我们要指定的远程分域需要自己的子网。

<p class="message--important"><strong></strong>重要信息：您不应该采用 <code>172.17.0.0/16</code>，因为它是 dockers 内部网络默认设置，这会导致问题。</p>

若要在我们的管理节点和远程分域之间进行清晰分离，我们将采用 `10.128.0.0/16` 作为我们的远程分域子网。此外，我们将使用 [map 变量](https://www.terraform.io/docs/configuration-0-11/variables.html#maps) 将网络分配至分域。这将使将来在添加其他区域时更加容易。

现在，本地部分将如下所示

```hcl
#...

// lets define variables which are shared between all regions
locals {
  ssh_public_key_file       = "~/.ssh/id_rsa.pub"
  cluster_name              = "my-dcos-demo"
  admin_ips                 = ["${data.http.whatismyip.body}/32"]

  region_networks = {
    // dont use 172.17/26 as its used by docker.
    "master"    = "172.12.0.0/16" // this is the default
    "West US 2" = "10.128.0.0/16"
  }
}

#...
```

## 远程分域
在我们开始更改 `dcos` 模块内的值之前，我们将把远程分域的基础架构定义附加到您的 `main.tf`。在我们的示例中，我们只希望在远程分域钟拥有专用代理节点，而专用和公共代理节点均可放置在远程分域中。

<p class="message--important"><strong></strong>重要信息：不支持在远程分域中运行管理节点实例。</p>

若要仅启动专用代理节点，我们将设置 `num_bootstrap = 0`、`num_masters = 0` 和 `num_public_agents = 0`。

另一个要提及的重要主题是命名。为了区分主要分域和远程分域的实例，我们引入 `name_prefix` 变量，这允许您为每个资源名称添加前缀。在本示例中，我们将 `name_prefix` 设置为远程分域的简称。

在以下示例中，您还将找到在模块调用中使用的 [共享配置选项](#shared-config-options)（被示例 `local.ssh_public_key_file` 所引用）。

```hcl
#...

module "dcos-wus2" {
  source  = "dcos-terraform/infrastructure/azurerm"
  version = "~> 0.2.0"

  providers = {
    azure = "azure"
  }

  location                          = "West US 2"
  avset_platform_fault_domain_count = 2
  subnet_range                      = "${local.region_networks["West US 2"]}"

  admin_ips   = ["${local.admin_ips}"]
  name_prefix = "wus2"

  cluster_name = "${local.cluster_name}"

  num_bootstrap      = 0
  num_masters        = 0
  num_private_agents = 1
  num_public_agents  = 0

  ssh_public_key_file    = "${local.ssh_public_key_file}"
}

```

## 对等主要 DC/OS 分域
我们现在需要在两个基础架构之间建立联系。Universal 安装工具为此任务提供模块。在该模块中，我们将介绍来自两个基础架构的数据：包含 DC/OS 管理节点的主要分域和包含远程专用代理节点的远程分域。

该模块需要接收的唯一信息是 `dcos` 和 `dcos-wus2` 模块输出。我们将把该模块附加到 `main.tf` 的末尾

这是示例 vnet-peering-section

```hcl
#...

module "vnet-connection-master-wus2" {
  source  = "dcos-terraform/vnet-peering/azurerm"
  version = "~> 0.2.0"

  providers = {
    azure = "azure"
  }

  cluster_name               = "${local.cluster_name}"
  local_region_network       = "master"
  local_resource_group_name  = "${module.dcos.infrastructure.resource_group_name}"
  local_vnet_name            = "${module.dcos.infrastructure.vnet_name}"
  local_vnet_id              = "${module.dcos.infrastructure.vnet_id}"
  remote_region_network      = "wus2"
  remote_resource_group_name = "${module.dcos-wus2.resource_group_name}"
  remote_vnet_name           = "${module.dcos-wus2.vnet_name}"
  remote_vnet_id             = "${module.dcos-wus2.vnet_id}"
}
```

## 对 dcos 模块的更改
此时，需要更改 `dcos` 模块，以便它了解远程分域并能够安装远程代理节点。

1. 选择子网范围。通常，不需要进行此更改，但是我们希望使您的示例非常具体。

    `subnet_range = "${local.region_networks["master"]}"`

2. 更改 cluster_name。由于这是共享资源，我们将使用本地变量。

    `cluster_name = "${local.cluster_name}"`

3. 列出 SSH 密钥。这也是共享资源，我们可使用本地变量

    `ssh_public_key_file = "${local.ssh_public_key_file}"`

4. 按照相同的模式添加管理 IP。

    `admin_ips = ["${local.admin_ips}"`]

5. 添加专用代理节点。这几乎是最重要的新变量。这告诉 DC/OS 安装模块需要安装哪些其他代理节点。

    `additional_private_agent_ips = ["${module.dcos-wus2.private_agents.private_ips}"]`

### 示例 dcos 模块
在应用上述更改后，您的 `dcos` 模块应如下所示

```hcl
module "dcos" {
  source  = "dcos-terraform/dcos/azurerm"
  version = "~> 0.2.0"

  providers = {
    azure = "azure"
  }

  location                          = "West US"
  avset_platform_fault_domain_count = 3
  subnet_range                      = "${local.region_networks["master"]}"

  cluster_name        = "${local.cluster_name}"
  ssh_public_key_file = "${local.ssh_public_key_file}"
  admin_ips           = ["${local.admin_ips}"]

  num_masters        = 3
  num_private_agents = 2
  num_public_agents  = 1

  dcos_version = "1.13.3"

  dcos_variant              = "ee"
  dcos_license_key_contents = "${file("./license.txt")}"

  # Make sure to set your credentials if you do not want the default EE
  # dcos_superuser_username      = "superuser-name"
  # dcos_superuser_password_hash = "${file("./dcos_superuser_password_hash.sha512")}"

  dcos_instance_os = "centos_7.6"

  additional_private_agent_ips = ["${module.dcos-wus2.private_agents.private_ips}"]
}
```

# 完整的 main.tf 示例
这是完成本指南后应该看到的完整 `main.tf`。

```hcl
provider "azure" {}

# Used to determine your public IP for forwarding rules
data "http" "whatismyip" {
  url = "http://whatismyip.akamai.com/"
}


// lets define variables which are shared between all regions
locals {
  ssh_public_key_file       = "~/.ssh/id_rsa.pub"
  cluster_name              = "my-dcos-demo"
  admin_ips                 = ["${data.http.whatismyip.body}/32"]

  region_networks = {
    // dont use 172.17/26 as its used by docker.
    "master"    = "172.12.0.0/16" // this is the default
    "West US 2" = "172.13.0.0/16"
  }
}

module "dcos" {
  source  = "dcos-terraform/dcos/azurerm"
  version = "~> 0.2.0"

  providers = {
    azure = "azure"
  }

  location                          = "West US"
  avset_platform_fault_domain_count = 3
  subnet_range                      = "${local.region_networks["master"]}"

  cluster_name        = "${local.cluster_name}"
  ssh_public_key_file = "${local.ssh_public_key_file}"
  admin_ips           = ["${local.admin_ips}"]

  num_masters        = 3
  num_private_agents = 2
  num_public_agents  = 1

  dcos_version = "1.13.3"

  dcos_variant              = "ee"
  dcos_license_key_contents = "${file("./license.txt")}"

  # Make sure to set your credentials if you do not want the default EE
  # dcos_superuser_username      = "superuser-name"
  # dcos_superuser_password_hash = "${file("./dcos_superuser_password_hash.sha512")}"

  dcos_instance_os = "centos_7.6"

  additional_private_agent_ips = ["${module.dcos-wus2.private_agents.private_ips}"]
}

output "masters-ips" {
  value = "${module.dcos.masters-ips}"
}

output "cluster-address" {
  value = "${module.dcos.masters-loadbalancer}"
}

output "public-agents-loadbalancer" {
  value = "${module.dcos.public-agents-loadbalancer}"
}

module "dcos-usw2" {
  source  = "dcos-terraform/infrastructure/azurerm"
  version = "~> 0.2.0"

  providers = {
    azure = "azure"
  }

  location                          = "West US 2"
  avset_platform_fault_domain_count = 2
  subnet_range                      = "${local.region_networks["West US 2"]}"

  admin_ips   = ["${local.admin_ips}"]
  name_prefix = "wus2"

  cluster_name = "${local.cluster_name}"

  num_bootstrap      = 0
  num_masters        = 0
  num_private_agents = 1
  num_public_agents  = 0

  ssh_public_key_file    = "${local.ssh_public_key_file}"
}

module "vnet-connection-master-wus2" {
  source  = "dcos-terraform/vnet-peering/azurerm"
  version = "~> 0.2.0"

  providers = {
    azure = "azure"
  }

  cluster_name               = "${local.cluster_name}"
  local_region_network       = "master"
  local_resource_group_name  = "${module.dcos.infrastructure.resource_group_name}"
  local_vnet_name            = "${module.dcos.infrastructure.vnet_name}"
  local_vnet_id              = "${module.dcos.infrastructure.vnet_id}"
  remote_region_network      = "wus2"
  remote_resource_group_name = "${module.dcos-wus2.resource_group_name}"
  remote_vnet_name           = "${module.dcos-wus2.vnet_name}"
  remote_vnet_id             = "${module.dcos-wus2.vnet_id}"
}
```
